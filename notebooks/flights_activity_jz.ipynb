{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewxvZV6LIvTW"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# Upload the file from your local machine\n",
        "# uploaded = files.upload()\n",
        "\n",
        "filepath = \"../data/flights.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibxGLGPxJDOd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the \"flights\" dataset is already loaded or available for upload\n",
        "# Read the uploaded file into a Pandas DataFrame\n",
        "# flights_data = pd.read_csv(next(iter(uploaded)), sep=\",\")\n",
        "flights_data = pd.read_csv(filepath, sep=\",\")\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(flights_data.head())\n",
        "\n",
        "# Call shape to identify the rows and columns of the dataset\n",
        "print('Flights dataset has', flights_data.shape[0], 'rows and', flights_data.shape[1], 'columns')\n",
        "\n",
        "# Get the list of features (columns)\n",
        "features_list = flights_data.columns.tolist()\n",
        "print(\"List of features:\")\n",
        "print(features_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8O3BT6gk15w"
      },
      "outputs": [],
      "source": [
        "#Check the data for inconsistencies\n",
        "import pandas as pd\n",
        "\n",
        "# Check for missing values in each column\n",
        "missing_values = flights_data.isnull().sum()\n",
        "\n",
        "# Identify columns with missing values\n",
        "columns_with_missing_values = missing_values[missing_values > 0].index\n",
        "\n",
        "# Print columns with missing values and their count\n",
        "for column in columns_with_missing_values:\n",
        "    print(f\"Column '{column}' has {missing_values[column]} missing values.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVT6LYk4mGg6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Frequency table\n",
        "origin_frequency = flights_data['origin'].value_counts()\n",
        "\n",
        "# Print frequency table\n",
        "print(\"Frequency Table for 'origin' feature:\")\n",
        "print(origin_frequency)\n",
        "\n",
        "# Bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "origin_frequency.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "plt.title('Bar Chart for Origin Feature')\n",
        "plt.xlabel('Origin')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqrN4pDimP-3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxO5KP-K_9tj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming the \"flights\" dataset is already loaded or available for upload\n",
        "# Assuming the dataset is stored in the variable flights_data\n",
        "\n",
        "# Extract the features for PCA\n",
        "features = flights_data[['dep_time', 'sched_dep_time', 'dep_delay', 'arr_time',\n",
        "                          'sched_arr_time', 'arr_delay', 'air_time', 'distance',\n",
        "                          'hour', 'minute']]\n",
        "\n",
        "# Impute missing values (replace NaNs with the mean of each column)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "# Standardize the features\n",
        "features_standardized = StandardScaler().fit_transform(features_imputed)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "principal_components = pca.fit_transform(features_standardized)\n",
        "\n",
        "# Print explained variance ratio for each principal component\n",
        "print(\"Explained Variance Ratio:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# Get the eigenvalues and explained variance ratios\n",
        "eigenvalues = pca.explained_variance_\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Scree Plot\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o', linestyle='-', color='b')\n",
        "plt.axvline(x=7, color='r', linestyle='--', label='k = 6')  # Vertical line at k = 7\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Cumulative Explained Variance Ratio Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(explained_variance_ratio) + 1), np.cumsum(explained_variance_ratio), marker='o', linestyle='-', color='b')\n",
        "threshold_index = np.argmax(np.cumsum(explained_variance_ratio) >= 0.95) + 1\n",
        "plt.axvline(x=threshold_index, color='r', linestyle='--', label='95% Threshold')  # Vertical line at threshold\n",
        "plt.title('Cumulative Explained Variance Ratio')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEf6z4hGTdbA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA()\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Get the eigenvalues and explained variance ratios\n",
        "eigenvalues = pca.explained_variance_\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Scree Plot\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o', linestyle='-', color='b')\n",
        "plt.axvline(x=7, color='r', linestyle='--', label='k = 7')  # Vertical line at k = 7\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Eigenvalue')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Cumulative Explained Variance Ratio Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(explained_variance_ratio) + 1), np.cumsum(explained_variance_ratio), marker='o', linestyle='-', color='b')\n",
        "threshold_index = np.argmax(np.cumsum(explained_variance_ratio) >= 0.95) + 1\n",
        "plt.axvline(x=threshold_index, color='r', linestyle='--', label='95% Threshold')  # Vertical line at threshold\n",
        "plt.title('Cumulative Explained Variance Ratio')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOBWGuc6bZUV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA()\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Get the coefficients for the first principal component (PC1)\n",
        "coef_pc1 = pca.components_[0]\n",
        "\n",
        "# Display the rounded coefficients\n",
        "print(\"Coefficients for PC1:\")\n",
        "print(np.round(coef_pc1, 2))\n",
        "\n",
        "# Construct the equation for PC1\n",
        "equation_pc1 = \"PC1 = \"\n",
        "for i, coef in enumerate(coef_pc1):\n",
        "    equation_pc1 += f\"{np.round(coef, 2)} * X{i+1} + \" if i < len(coef_pc1) - 1 else f\"{np.round(coef, 2)} * X{i+1}\"\n",
        "\n",
        "# Display the equation for PC1\n",
        "print(\"\\nEquation for PC1:\")\n",
        "print(equation_pc1)\n",
        "\n",
        "# Substitute the first samples of each feature into the equation for PC1\n",
        "first_samples = X_standardized[0, :]\n",
        "pc1_value = np.dot(first_samples, coef_pc1)\n",
        "\n",
        "# Display the result\n",
        "print(\"\\nPC1 Value for the First Sample:\")\n",
        "print(np.round(pc1_value, 4))\n",
        "\n",
        "# Display the explanation for how the first eigenvalue is computed\n",
        "print(\"\\nExplanation for Computing the First Eigenvalue:\")\n",
        "print(\"The first eigenvalue is the amount of variance captured by the first principal component (PC1).\")\n",
        "print(\"It is obtained from the diagonal element of the covariance matrix of the standardized data.\")\n",
        "print(\"Mathematically, the first eigenvalue is equal to the square of the length (norm) of the first eigenvector (PC1).\")\n",
        "print(f\"First Eigenvalue: {np.round(pca.explained_variance_[0], 4)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObtOB1HtdJu9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Convert to DataFrame for better visualization (optional)\n",
        "df = pd.DataFrame(data=np.c_[X_standardized, y], columns=list(breast_cancer.feature_names) + ['target'])\n",
        "\n",
        "# Calculate the covariance matrix\n",
        "cov_matrix = np.cov(X_standardized, rowvar=False)\n",
        "\n",
        "# Display the covariance matrix\n",
        "print(\"Covariance Matrix:\")\n",
        "print(cov_matrix)\n",
        "\n",
        "# Perform eigendecomposition\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "# Get the coefficients for the first principal component (PC1)\n",
        "coef_pc1 = eigenvectors[:, 0]\n",
        "\n",
        "# Display the rounded coefficients for PC1\n",
        "print(\"\\nCoefficients for PC1:\")\n",
        "print(np.round(coef_pc1, 6))\n",
        "\n",
        "# Calculate the sum of squares of PC1 coefficients\n",
        "sum_of_squares = np.sum(coef_pc1**2)\n",
        "\n",
        "# Number of samples\n",
        "N = X_standardized.shape[0]\n",
        "\n",
        "# Calculate the first eigenvalue\n",
        "eigenvalue = (1 / N) * sum_of_squares\n",
        "\n",
        "# Display the result\n",
        "print(\"\\nFirst Eigenvalue:\")\n",
        "print(np.round(eigenvalue, 6))\n",
        "\n",
        "# Compute the sum of squares for PC1\n",
        "ss_pc1 = np.sum(principal_components[:, 0]**2)\n",
        "\n",
        "# Compute the eigenvalue for PC1\n",
        "eigenvalue_pc1 = ss_pc1 / (X_standardized.shape[0] - 1)\n",
        "\n",
        "# Display the result\n",
        "print(\"Eigenvalue for PC1 (computed):\", np.round(eigenvalue_pc1, 4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK9vhTVkbQQ8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "feature_names = breast_cancer.feature_names\n",
        "\n",
        "# Create a DataFrame for the original features\n",
        "features = pd.DataFrame(X, columns=feature_names)\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA()\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Create a DataFrame for principal component coefficients\n",
        "df_comp = pd.DataFrame(pca.components_, index=[f'PC{i+1}' for i in range(pca.n_components_)], columns=features.columns)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame with Principal Component Coefficients:\")\n",
        "print(df_comp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1EAiEs5b9dd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Select two features for visualization\n",
        "feature1_index = 0\n",
        "feature2_index = 7\n",
        "\n",
        "# Extract the selected features\n",
        "X_selected = X[:, [feature1_index, feature2_index]]\n",
        "\n",
        "# Standardize the features (important for PCA)\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X_selected)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Plot the original and transformed data points side by side\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot the original data points\n",
        "for label in np.unique(y):\n",
        "    axs[0].scatter(X_standardized[y == label, 0], X_standardized[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[0].set_title('Original Data Points')\n",
        "axs[0].set_xlabel(f'Feature {feature1_index + 1}')\n",
        "axs[0].set_ylabel(f'Feature {feature2_index + 1}')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot the transformed data points after PCA\n",
        "for label in np.unique(y):\n",
        "    axs[1].scatter(X_pca[y == label, 0], X_pca[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[1].set_title('Transformed Data Points after PCA')\n",
        "axs[1].set_xlabel('Principal Component 1')\n",
        "axs[1].set_ylabel('Principal Component 2')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8DZ-GdKe1Ve"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_standardized, X_pca, and y are defined\n",
        "# feature1_index and feature2_index are assumed to be defined as well\n",
        "\n",
        "# Convert NumPy arrays to DataFrames\n",
        "df_standardized = pd.DataFrame(X_standardized, columns=[f'Feature_{i+1}' for i in range(X_standardized.shape[1])])\n",
        "df_pca = pd.DataFrame(X_pca, columns=['Principal_Component_1', 'Principal_Component_2'])\n",
        "\n",
        "# Plot the original and transformed data points side by side with density plots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plot the original data points with density plot\n",
        "for label in np.unique(y):\n",
        "    sns.kdeplot(data=df_standardized[y == label], x='Feature_1', y='Feature_2', label=f'Class {label}', ax=axs[0], fill=True, alpha=0.5)\n",
        "    axs[0].scatter(X_standardized[y == label, 0], X_standardized[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[0].set_title('Original Data Points with Density Plot')\n",
        "axs[0].set_xlabel(f'Feature {feature1_index + 1}')\n",
        "axs[0].set_ylabel(f'Feature {feature2_index + 1}')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "# Plot the transformed data points after PCA with density plot\n",
        "for label in np.unique(y):\n",
        "    sns.kdeplot(data=df_pca[y == label], x='Principal_Component_1', y='Principal_Component_2', label=f'Class {label}', ax=axs[1], fill=True, alpha=0.5)\n",
        "    axs[1].scatter(X_pca[y == label, 0], X_pca[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[1].set_title('Transformed Data Points after PCA with Density Plot')\n",
        "axs[1].set_xlabel('Principal Component 1')\n",
        "axs[1].set_ylabel('Principal Component 2')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXkapulsf982"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Select two features for visualization\n",
        "feature1_index = 0\n",
        "feature2_index = 7\n",
        "\n",
        "# Extract the selected features\n",
        "X_selected = X[:, [feature1_index, feature2_index]]\n",
        "\n",
        "# Standardize the features (important for PCA)\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X_selected)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Convert NumPy arrays to DataFrames\n",
        "df_original = pd.DataFrame(X_selected, columns=[f'Feature_{i+1}' for i in range(X_selected.shape[1])])\n",
        "df_standardized = pd.DataFrame(X_standardized, columns=[f'Feature_{i+1}' for i in range(X_standardized.shape[1])])\n",
        "df_pca = pd.DataFrame(X_pca, columns=['Principal_Component_1', 'Principal_Component_2'])\n",
        "\n",
        "# Plot the original and transformed data points side by side with density plots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 9))\n",
        "\n",
        "# Plot the original data points\n",
        "for label in np.unique(y):\n",
        "    axs[0, 0].scatter(X_standardized[y == label, 0], X_standardized[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[0, 0].set_title('Original Data Points')\n",
        "axs[0, 0].set_xlabel(f'Feature {feature1_index + 1}')\n",
        "axs[0, 0].set_ylabel(f'Feature {feature2_index + 1}')\n",
        "axs[0, 0].legend()\n",
        "axs[0, 0].grid(True)\n",
        "\n",
        "# Plot the transformed data points after PCA\n",
        "for label in np.unique(y):\n",
        "    axs[0, 1].scatter(X_pca[y == label, 0], X_pca[y == label, 1], label=f'Class {label}', edgecolor='k', alpha=0.8)\n",
        "axs[0, 1].set_title('Transformed Data Points after PCA')\n",
        "axs[0, 1].set_xlabel('Principal Component 1')\n",
        "axs[0, 1].set_ylabel('Principal Component 2')\n",
        "axs[0, 1].legend()\n",
        "axs[0, 1].grid(True)\n",
        "\n",
        "# Plot density plots for original data with both features\n",
        "for label in np.unique(y):\n",
        "    sns.kdeplot(data=df_original[y == label], x='Feature_1', y='Feature_2', ax=axs[1, 0], fill=True, alpha=0.5, label=f'Class {label}')\n",
        "axs[1, 0].set_title('Density Plot of Original Data (Features 1 and 8)')\n",
        "axs[1, 0].set_xlabel(f'Feature {feature1_index + 1}')\n",
        "axs[1, 0].set_ylabel(f'Feature {feature2_index + 1}')\n",
        "axs[1, 0].grid(True)\n",
        "\n",
        "# Assuming X_original is the original dataset you want to compare\n",
        "# Define the feature_indices you want to compare\n",
        "feature_indices = [0, 1]\n",
        "\n",
        "# Original Data\n",
        "df_original = pd.DataFrame(X[:, feature_indices], columns=[f'Feature_{i+1}' for i in feature_indices])\n",
        "\n",
        "# Standardize the data for comparison\n",
        "scaler_comparison = StandardScaler()\n",
        "X_standardized_comparison = scaler_comparison.fit_transform(X[:, feature_indices])\n",
        "df_standardized_comparison = pd.DataFrame(X_standardized_comparison, columns=[f'Feature_{i+1}' for i in feature_indices])\n",
        "\n",
        "# Plot density plots for standardized data for comparison\n",
        "for label in np.unique(y):\n",
        "    sns.kdeplot(data=df_standardized_comparison[y == label], x='Feature_1', y='Feature_2', ax=axs[1, 1], fill=True, alpha=0.5, label=f'Class {label}')\n",
        "axs[1, 1].set_title('Density Plot of Standardized Data for Comparison')\n",
        "axs[1, 1].set_xlabel(f'Feature {feature1_index + 1}')\n",
        "axs[1, 1].set_ylabel(f'Feature {feature2_index + 1}')\n",
        "axs[1, 1].grid(True)\n",
        "\n",
        "# Add legends separately\n",
        "axs[1, 0].legend()\n",
        "axs[1, 1].legend()\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeGgInp4iImO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "feature_names = breast_cancer.feature_names\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Perform PCA with 7 components\n",
        "num_components = 7\n",
        "pca = PCA(n_components=num_components)\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Create DataFrames for the coefficients of the first 7 principal components\n",
        "df_coef_pcs = pd.DataFrame(pca.components_[:num_components].T, columns=[f'PC{i+1}' for i in range(num_components)], index=feature_names)\n",
        "\n",
        "# Bar Plots for the first 7 PCs\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(num_components):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    sns.barplot(x=df_coef_pcs[f'PC{i+1}'], y=df_coef_pcs.index, hue=df_coef_pcs.index, palette='viridis', legend=False)\n",
        "    plt.title(f'Principal Component {i+1}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDAptbJ9FULB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m_aqfy8jIsL"
      },
      "outputs": [],
      "source": [
        "print(df_coef_pcs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cD29b8tnRvE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "feature_names = breast_cancer.feature_names\n",
        "\n",
        "# Standardize the features\n",
        "X_standardized = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Perform PCA with 7 components\n",
        "pca = PCA(n_components=7)\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Create a DataFrame combining PCs and target feature\n",
        "df_pcs = pd.DataFrame(data=np.c_[principal_components, y], columns=[f'PC{i+1}' for i in range(7)] + ['target'])\n",
        "\n",
        "# Plot bar plot for mean values\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    data=df_pcs.groupby('target').mean().stack().reset_index(name='value'),\n",
        "    x='level_1',\n",
        "    y='value',\n",
        "    hue='target',\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Mean Values of Principal Components for Malignant and Benign Tumors')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Mean Value')\n",
        "plt.legend(title='Target', labels=['Malignant (0.0)', 'Benign (1.0)'])\n",
        "plt.show()\n",
        "\n",
        "# Plot bar plot for standard deviation values\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    data=df_pcs.groupby('target').std().stack().reset_index(name='value'),\n",
        "    x='level_1',\n",
        "    y='value',\n",
        "    hue='target',\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Standard Deviation Values of Principal Components for Malignant and Benign Tumors')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Standard Deviation')\n",
        "plt.legend(title='Target', labels=['Malignant (0.0)', 'Benign (1.0)'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHsfg30lrM3G"
      },
      "outputs": [],
      "source": [
        "print(df_pcs.groupby('target').std().stack().reset_index(name='value'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR2pekiwFULC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}